{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, ZeroPadding3D, Conv3D, BatchNormalization, Activation, SpatialDropout3D, MaxPooling3D, \\\n",
    "    TimeDistributed, Flatten, Bidirectional, GRU, Dense, AveragePooling3D\n",
    "from keras import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(gpus)\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        \n",
    "import keras\n",
    "import numpy as np\n",
    "from data_gen_stanford import DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Lipnet(n_classes=51, summary=False):\n",
    "    input_layer = Input(name='the_input', shape=(75, 50, 100, 3), dtype='float32')\n",
    "    x = Conv3D(32, (3, 5, 5), strides=(1, 2, 2), padding=\"same\", kernel_initializer='he_normal', name='conv1')(input_layer)\n",
    "    x = BatchNormalization(name='batc1')(x)\n",
    "    x = Activation('relu', name='actv1')(x)\n",
    "    x = SpatialDropout3D(0.5)(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max1')(x)\n",
    "\n",
    "    x = Conv3D(64, (3, 5, 5), strides=(1, 1, 1), padding=\"same\", kernel_initializer='he_normal', name='conv2')(x)\n",
    "    x = BatchNormalization(name='batc2')(x)\n",
    "    x = Activation('relu', name='actv2')(x)\n",
    "    x = SpatialDropout3D(0.5)(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max2')(x)\n",
    "\n",
    "    x = Conv3D(96, (3, 3, 3), strides=(1, 1, 1), padding=\"same\", kernel_initializer='he_normal', name='conv3')(x)\n",
    "    x = BatchNormalization(name='batc3')(x)\n",
    "    x = Activation('relu', name='actv3')(x)\n",
    "    x = SpatialDropout3D(0.5)(x)\n",
    "    x = MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name='max3')(x)\n",
    "    \n",
    "    x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "    x = Bidirectional(GRU(128, return_sequences=True, kernel_initializer='Orthogonal', name='gru1'),\n",
    "                            merge_mode='concat')(x)\n",
    "    x = Bidirectional(GRU(128, return_sequences=True, kernel_initializer='Orthogonal', name='gru2'),\n",
    "                            merge_mode='concat')(x)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(n_classes, kernel_initializer='he_normal', name='dense1', activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=outputs)\n",
    "    if summary:\n",
    "        keras.utils.plot_model(model, 'network.png', show_shapes=True)\n",
    "        print(model.summary())\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(beta_1=0.9, beta_2=0.999, lr=1e-4),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', 'mse', tf.keras.metrics.AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "[28516, 9013, 15724, 11100, 13956, 571, 26280, 21982, 20736, 26575]\n",
      "max240.0\n",
      "min0.0\n",
      "[24665, 15378, 11097, 23836, 5893, 10035, 1633, 26485, 21176, 30988]\n",
      "max247.0\n",
      "min0.0\n",
      "[14034, 27503, 21321, 25613, 332, 11153, 7727, 25895, 28201, 20629]\n",
      "max237.0\n",
      "min0.0\n",
      "[24409, 9082, 10239, 5780, 737, 9301, 3031, 14959, 28623, 7571]\n",
      "max246.0\n",
      "min0.0\n",
      "[31909, 110, 19784, 18601, 23149, 23746, 22005, 12631, 16621, 31459]\n",
      "max240.0\n",
      "min0.0\n",
      "[9027, 31944, 29787, 17045, 20202, 11670, 26255, 13381, 876, 23936]\n",
      "max226.0\n",
      "min0.0\n",
      "[13902, 19450, 17396, 4981, 25875, 10383, 15858, 12394, 21967, 21827]\n",
      "max237.0\n",
      "min0.0\n",
      "[6043, 613, 31691, 3665, 22972, 23943, 10350, 20406, 32410, 20607]\n",
      "max252.0\n",
      "min0.0\n",
      "[27549, 16821, 11346, 18444, 24070, 12396, 2678, 21313, 28205, 9279]\n",
      "max255.0\n",
      "min0.0\n",
      "[27080, 24587, 21892, 667, 5962, 4785, 6534, 7044, 19093, 9524]\n",
      "max249.0\n",
      "min0.0\n",
      "[11734, 11326, 10201, 6878, 1936, 30149, 3067, 5168, 9767, 19620]\n",
      "max255.0\n",
      "min0.0\n",
      "[2715, 6056, 32299, 4874, 22271, 31626, 30088, 8716, 22237, 25042]\n",
      "max255.0\n",
      "min0.0\n",
      "   1/3281 [..............................] - ETA: 5:23:21 - loss: 0.7036 - accuracy: 0.5529 - mse: 0.2537 - auc: 0.5302[8827, 17841, 29029, 3733, 31835, 3081, 24801, 12076, 21315, 14059]\n",
      "max231.0\n",
      "min0.0\n",
      "   2/3281 [..............................] - ETA: 2:50:18 - loss: 0.6374 - accuracy: 0.6353 - mse: 0.2233 - auc: 0.5324[23297, 12716, 12772, 4449, 22602, 7104, 14871, 30078, 4807, 14948]\n",
      "max255.0\n",
      "min0.0\n",
      "   3/3281 [..............................] - ETA: 1:59:22 - loss: 0.5912 - accuracy: 0.6902 - mse: 0.2022 - auc: 0.5380[17249, 5954, 25508, 26752, 8946, 5519, 26982, 14872, 20386, 21068]\n",
      "max230.0\n",
      "min0.0\n",
      "   4/3281 [..............................] - ETA: 1:33:48 - loss: 0.5412 - accuracy: 0.7363 - mse: 0.1807 - auc: 0.5449[14447, 11703, 13932, 29947, 18379, 9932, 18553, 11415, 22863, 3458]\n",
      "max246.0\n",
      "min0.0\n",
      "   5/3281 [..............................] - ETA: 1:18:31 - loss: 0.5107 - accuracy: 0.7631 - mse: 0.1675 - auc: 0.5472[5312, 9640, 20304, 8813, 1303, 10153, 9182, 18046, 16999, 28203]\n",
      "max249.0\n",
      "min0.0\n",
      "   6/3281 [..............................] - ETA: 1:08:18 - loss: 0.4850 - accuracy: 0.7824 - mse: 0.1570 - auc: 0.5490[18488, 22282, 12842, 16023, 851, 23026, 24130, 6401, 22534, 4752]\n",
      "max233.0\n",
      "min0.0\n",
      "   7/3281 [..............................] - ETA: 1:01:00 - loss: 0.4661 - accuracy: 0.7964 - mse: 0.1489 - auc: 0.5511[3628, 17298, 17601, 29624, 9938, 19130, 16668, 15185, 3303, 31938]\n",
      "max230.0\n",
      "min0.0\n",
      "   8/3281 [..............................] - ETA: 55:34 - loss: 0.4512 - accuracy: 0.8069 - mse: 0.1429 - auc: 0.5537  [17443, 24990, 18574, 10774, 29845, 14163, 17546, 1193, 30608, 15048]\n",
      "max238.0\n",
      "min0.0\n",
      "   9/3281 [..............................] - ETA: 51:19 - loss: 0.4405 - accuracy: 0.8153 - mse: 0.1379 - auc: 0.5566[24271, 23486, 25595, 15744, 18424, 20330, 4859, 6083, 28073, 9324]\n",
      "max247.0\n",
      "min0.0\n",
      "  10/3281 [..............................] - ETA: 47:56 - loss: 0.4338 - accuracy: 0.8220 - mse: 0.1344 - auc: 0.5595[29667, 19263, 26330, 4380, 14310, 14316, 27723, 24342, 16435, 31487]\n",
      "max254.0\n",
      "min0.0\n",
      "  11/3281 [..............................] - ETA: 45:07 - loss: 0.4270 - accuracy: 0.8271 - mse: 0.1314 - auc: 0.5627[13, 12822, 11231, 31483, 31757, 3234, 31946, 2866, 22775, 6677]\n",
      "max226.0\n",
      "min0.0\n",
      "  12/3281 [..............................] - ETA: 42:49 - loss: 0.4231 - accuracy: 0.8317 - mse: 0.1293 - auc: 0.5657[22774, 2231, 18593, 16257, 9582, 26277, 16692, 10802, 26790, 27862]\n",
      "max252.0\n",
      "min0.0\n",
      "  13/3281 [..............................] - ETA: 40:52 - loss: 0.4197 - accuracy: 0.8345 - mse: 0.1274 - auc: 0.5688[2312, 13483, 27639, 17978, 31767, 17002, 3129, 3326, 11657, 2206]\n",
      "max240.0\n",
      "min0.0\n",
      "  14/3281 [..............................] - ETA: 39:11 - loss: 0.4159 - accuracy: 0.8368 - mse: 0.1257 - auc: 0.5719[22308, 16171, 7226, 23584, 14808, 27257, 18861, 768, 29188, 11487]\n",
      "max250.0\n",
      "min0.0\n",
      "  15/3281 [..............................] - ETA: 37:43 - loss: 0.4114 - accuracy: 0.8392 - mse: 0.1241 - auc: 0.5752[17942, 3359, 18027, 2339, 8011, 29986, 16214, 3848, 3880, 14363]\n",
      "max255.0\n",
      "min0.0\n",
      "  16/3281 [..............................] - ETA: 36:28 - loss: 0.4073 - accuracy: 0.8412 - mse: 0.1225 - auc: 0.5786[9500, 20617, 18705, 1387, 19779, 20490, 28825, 10550, 19995, 20753]\n",
      "max240.0\n",
      "min0.0\n",
      "  17/3281 [..............................] - ETA: 35:20 - loss: 0.4047 - accuracy: 0.8430 - mse: 0.1214 - auc: 0.5820[17308, 21881, 9374, 20134, 24750, 16669, 7531, 21446, 11344, 12565]\n",
      "max251.0\n",
      "min0.0\n",
      "  18/3281 [..............................] - ETA: 34:20 - loss: 0.4028 - accuracy: 0.8437 - mse: 0.1206 - auc: 0.5852[22540, 24388, 21887, 31092, 18039, 24778, 9800, 11188, 27390, 7436]\n",
      "max246.0\n",
      "min0.0\n",
      "  19/3281 [..............................] - ETA: 33:25 - loss: 0.4010 - accuracy: 0.8444 - mse: 0.1199 - auc: 0.5883[21338, 29979, 30785, 14795, 21002, 20007, 26316, 27500, 25210, 6562]\n",
      "max246.0\n",
      "min0.0\n",
      "  20/3281 [..............................] - ETA: 32:36 - loss: 0.3990 - accuracy: 0.8457 - mse: 0.1192 - auc: 0.5912[22517, 15394, 23284, 7556, 23981, 12976, 29473, 15188, 5633, 16475]\n",
      "max236.0\n",
      "min0.0\n",
      "  21/3281 [..............................] - ETA: 31:51 - loss: 0.3960 - accuracy: 0.8471 - mse: 0.1182 - auc: 0.5940[16385, 17580, 14559, 8574, 27340, 13988, 21235, 4888, 10295, 10294]\n",
      "max246.0\n",
      "min0.0\n",
      "  22/3281 [..............................] - ETA: 31:12 - loss: 0.3954 - accuracy: 0.8480 - mse: 0.1178 - auc: 0.5966[28433, 17574, 31907, 27485, 17361, 19012, 25051, 29658, 22945, 6946]\n",
      "max238.0\n",
      "min0.0\n",
      "  23/3281 [..............................] - ETA: 30:35 - loss: 0.3932 - accuracy: 0.8488 - mse: 0.1171 - auc: 0.5992[28983, 4524, 32709, 25829, 2381, 5691, 30384, 8316, 22785, 29872]\n",
      "max234.0\n",
      "min0.0\n",
      "  24/3281 [..............................] - ETA: 30:03 - loss: 0.3913 - accuracy: 0.8502 - mse: 0.1165 - auc: 0.6016[7781, 21232, 32333, 23794, 9924, 7886, 30324, 1358, 25793, 12955]\n",
      "max253.0\n",
      "min0.0\n",
      "  25/3281 [..............................] - ETA: 29:35 - loss: 0.3897 - accuracy: 0.8514 - mse: 0.1159 - auc: 0.6038[26663, 10103, 13603, 18232, 24219, 4745, 312, 5444, 26214, 8055]\n",
      "max240.0\n",
      "min0.0\n",
      "  26/3281 [..............................] - ETA: 29:08 - loss: 0.3882 - accuracy: 0.8523 - mse: 0.1154 - auc: 0.6060[28538, 25282, 589, 29070, 26991, 18376, 14018, 691, 3779, 25394]\n",
      "max233.0\n",
      "min0.0\n",
      "  27/3281 [..............................] - ETA: 28:46 - loss: 0.3865 - accuracy: 0.8529 - mse: 0.1150 - auc: 0.6080[18803, 7677, 15903, 27261, 4035, 16856, 28896, 29456, 16014, 22509]\n",
      "max241.0\n",
      "min0.0\n",
      "  28/3281 [..............................] - ETA: 28:25 - loss: 0.3854 - accuracy: 0.8539 - mse: 0.1146 - auc: 0.6099[10302, 23435, 25978, 7694, 13049, 17961, 2488, 31042, 28519, 11816]\n",
      "max249.0\n",
      "min0.0\n",
      "  29/3281 [..............................] - ETA: 28:05 - loss: 0.3837 - accuracy: 0.8547 - mse: 0.1141 - auc: 0.6118[15182, 32681, 5547, 17244, 25127, 3135, 16634, 22803, 3255, 3793]\n",
      "max249.0\n",
      "min0.0\n",
      "  30/3281 [..............................] - ETA: 27:45 - loss: 0.3817 - accuracy: 0.8555 - mse: 0.1135 - auc: 0.6136[26056, 1076, 11915, 9739, 26545, 23508, 14173, 10945, 5147, 12145]\n",
      "max233.0\n",
      "min0.0\n",
      "  31/3281 [..............................] - ETA: 27:28 - loss: 0.3810 - accuracy: 0.8564 - mse: 0.1132 - auc: 0.6153[27332, 8895, 2466, 8089, 25688, 4122, 8742, 20492, 4972, 7766]\n",
      "max243.0\n",
      "min0.0\n",
      "  32/3281 [..............................] - ETA: 27:10 - loss: 0.3800 - accuracy: 0.8572 - mse: 0.1129 - auc: 0.6168[24028, 16868, 4134, 27306, 3321, 13178, 30493, 17704, 24133, 26684]\n",
      "max255.0\n",
      "min0.0\n",
      "  33/3281 [..............................] - ETA: 26:53 - loss: 0.3791 - accuracy: 0.8578 - mse: 0.1126 - auc: 0.6183[12306, 24298, 23622, 12918, 16535, 16001, 29463, 27921, 28359, 21470]\n",
      "max237.0\n",
      "min0.0\n",
      "  34/3281 [..............................] - ETA: 26:38 - loss: 0.3778 - accuracy: 0.8584 - mse: 0.1122 - auc: 0.6198[31801, 31129, 32428, 8997, 14574, 4046, 23379, 13862, 6343, 14901]\n",
      "max245.0\n",
      "min0.0\n",
      "  35/3281 [..............................] - ETA: 26:22 - loss: 0.3773 - accuracy: 0.8589 - mse: 0.1120 - auc: 0.6212[6516, 25956, 12176, 16953, 16760, 26167, 19458, 8024, 31261, 17768]\n",
      "max244.0\n",
      "min0.0\n",
      "  36/3281 [..............................] - ETA: 26:08 - loss: 0.3758 - accuracy: 0.8595 - mse: 0.1115 - auc: 0.6225[14881, 18400, 21022, 7993, 1621, 11367, 8818, 13863, 10319, 19999]\n",
      "max237.0\n",
      "min0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  37/3281 [..............................] - ETA: 25:57 - loss: 0.3756 - accuracy: 0.8600 - mse: 0.1114 - auc: 0.6238[19205, 8820, 26620, 15447, 26218, 10488, 16322, 21621, 7587, 3996]\n",
      "max240.0\n",
      "min0.0\n",
      "  38/3281 [..............................] - ETA: 25:45 - loss: 0.3747 - accuracy: 0.8605 - mse: 0.1111 - auc: 0.6250[20765, 31788, 1894, 9093, 18388, 10271, 7509, 27412, 18023, 20161]\n",
      "max239.0\n",
      "min0.0\n",
      "  39/3281 [..............................] - ETA: 25:31 - loss: 0.3738 - accuracy: 0.8610 - mse: 0.1108 - auc: 0.6262[22453, 26031, 23197, 30643, 14263, 23397, 9084, 7590, 32175, 9183]\n",
      "max251.0\n",
      "min0.0\n",
      "  40/3281 [..............................] - ETA: 25:18 - loss: 0.3729 - accuracy: 0.8615 - mse: 0.1104 - auc: 0.6273[2788, 14551, 32390, 26304, 31608, 16538, 19689, 24077, 414, 12778]\n",
      "max240.0\n",
      "min0.0\n",
      "  41/3281 [..............................] - ETA: 25:06 - loss: 0.3727 - accuracy: 0.8618 - mse: 0.1102 - auc: 0.6284[11858, 19841, 14949, 17870, 29255, 30077, 5439, 97, 17539, 1296]\n",
      "max244.0\n",
      "min0.0\n",
      "  42/3281 [..............................] - ETA: 24:55 - loss: 0.3717 - accuracy: 0.8622 - mse: 0.1099 - auc: 0.6294[17685, 17238, 21477, 8743, 22844, 28561, 16835, 3534, 13970, 9806]\n",
      "max244.0\n",
      "min0.0\n",
      "  43/3281 [..............................] - ETA: 24:45 - loss: 0.3711 - accuracy: 0.8625 - mse: 0.1097 - auc: 0.6305[17285, 13512, 1749, 453, 13886, 25281, 14373, 155, 26907, 10804]\n",
      "max255.0\n",
      "min0.0\n",
      "  44/3281 [..............................] - ETA: 24:35 - loss: 0.3705 - accuracy: 0.8626 - mse: 0.1095 - auc: 0.6315[19685, 23351, 7832, 26580, 13292, 30823, 16559, 4769, 15079, 11790]\n",
      "max240.0\n",
      "min0.0\n",
      "  45/3281 [..............................] - ETA: 24:26 - loss: 0.3703 - accuracy: 0.8629 - mse: 0.1095 - auc: 0.6324[17731, 12129, 41, 5018, 12509, 14961, 9731, 29197, 31717, 5413]\n",
      "max238.0\n",
      "min0.0\n",
      "  46/3281 [..............................] - ETA: 24:15 - loss: 0.3698 - accuracy: 0.8632 - mse: 0.1093 - auc: 0.6333[25736, 1663, 30268, 10492, 5017, 15241, 22163, 17444, 27699, 1127]\n",
      "max245.0\n",
      "min0.0\n",
      "  47/3281 [..............................] - ETA: 24:07 - loss: 0.3693 - accuracy: 0.8634 - mse: 0.1091 - auc: 0.6342[7365, 19252, 9203, 6813, 4305, 13583, 22703, 26374, 26117, 5776]\n",
      "max246.0\n",
      "min0.0\n",
      "  48/3281 [..............................] - ETA: 23:58 - loss: 0.3689 - accuracy: 0.8637 - mse: 0.1090 - auc: 0.6351[]\n",
      "max0.0\n",
      "min0.0\n",
      "  49/3281 [..............................] - ETA: 23:51 - loss: 0.3683 - accuracy: 0.8641 - mse: 0.1087 - auc: 0.6359[4257, 20902, 18691, 1146, 23710, 17522, 8280, 22609, 6837, 6769]\n",
      "max247.0\n",
      "min0.0\n",
      "  50/3281 [..............................] - ETA: 23:43 - loss: 0.3675 - accuracy: 0.8645 - mse: 0.1085 - auc: 0.6367[16665, 32335, 24803, 2829, 16308, 565, 29010, 4402, 7982, 23073]\n",
      "max244.0\n",
      "min0.0\n",
      "  51/3281 [..............................] - ETA: 23:35 - loss: 0.3670 - accuracy: 0.8647 - mse: 0.1083 - auc: 0.6375[15613, 12346, 2572, 29580, 28344, 5159, 1865, 20957, 18843, 12933]\n",
      "max247.0\n",
      "min0.0\n",
      "  52/3281 [..............................] - ETA: 23:29 - loss: 0.3665 - accuracy: 0.8649 - mse: 0.1082 - auc: 0.6383[9151, 1118, 28866, 11817, 10890, 1772, 13901, 16622, 15671, 32468]\n",
      "max250.0\n",
      "min0.0\n",
      "  53/3281 [..............................] - ETA: 23:23 - loss: 0.3663 - accuracy: 0.8651 - mse: 0.1081 - auc: 0.6391[]\n",
      "max0.0\n",
      "min0.0\n",
      "  54/3281 [..............................] - ETA: 23:17 - loss: 0.3657 - accuracy: 0.8654 - mse: 0.1080 - auc: 0.6399[10718, 9488, 4078, 1088, 13842, 25877, 24052, 29098, 11553, 24638]\n",
      "max227.0\n",
      "min0.0\n",
      "  55/3281 [..............................] - ETA: 23:10 - loss: 0.3651 - accuracy: 0.8657 - mse: 0.1077 - auc: 0.6406[22208, 11162, 31795, 17426, 11276, 21857, 20110, 25894, 14460, 3995]\n",
      "max238.0\n",
      "min0.0\n",
      "  56/3281 [..............................] - ETA: 23:04 - loss: 0.3646 - accuracy: 0.8659 - mse: 0.1076 - auc: 0.6413[13275, 16759, 6982, 20105, 28749, 26451, 18276, 16512, 21000, 6363]\n",
      "max255.0\n",
      "min0.0\n",
      "  57/3281 [..............................] - ETA: 22:58 - loss: 0.3642 - accuracy: 0.8660 - mse: 0.1075 - auc: 0.6420[11716, 30118, 2517, 13607, 14174, 7668, 20471, 1872, 26655, 18694]\n",
      "max246.0\n",
      "min0.0\n",
      "  58/3281 [..............................] - ETA: 22:51 - loss: 0.3637 - accuracy: 0.8662 - mse: 0.1074 - auc: 0.6427[17667, 3784, 4705, 280, 26200, 4215, 2839, 17634, 7212, 17469]\n",
      "max232.0\n",
      "min0.0\n",
      "  59/3281 [..............................] - ETA: 22:45 - loss: 0.3633 - accuracy: 0.8665 - mse: 0.1073 - auc: 0.6434[25997, 2468, 402, 29191, 26931, 20733, 24477, 10506, 18279, 9039]\n",
      "max241.0\n",
      "min0.0\n",
      "  60/3281 [..............................] - ETA: 22:39 - loss: 20722485384.8906 - accuracy: 0.8666 - mse: 2568037535487621574164480.0000 - auc: 0.6441[26239, 10565, 28326, 12498, 26904, 25835, 24503, 21685, 10853, 26465]\n",
      "max245.0\n",
      "min0.0\n",
      "  61/3281 [..............................] - ETA: 22:33 - loss: 20382772509.7338 - accuracy: 0.8668 - mse: 2525938606746902556835840.0000 - auc: 0.6447[20914, 14095, 22720, 25253, 8208, 5811, 6568, 30346, 188, 9844]\n",
      "max234.0\n",
      "min0.0\n",
      "  62/3281 [..............................] - ETA: 22:28 - loss: 20054018114.4212 - accuracy: 0.8670 - mse: 2485197819538610405244928.0000 - auc: 0.6454[9092, 25699, 30610, 911, 1382, 26274, 28156, 3028, 1787, 29033]\n",
      "max240.0\n",
      "min0.0\n",
      "  63/3281 [..............................] - ETA: 22:23 - loss: 19735700366.5786 - accuracy: 0.8670 - mse: 2445750033797734832537600.0000 - auc: 0.6460[23295, 12004, 201, 2917, 14740, 5700, 21999, 30219, 13032, 4864]\n",
      "max249.0\n",
      "min0.0\n",
      "  64/3281 [..............................] - ETA: 22:18 - loss: 19427330048.3564 - accuracy: 0.8670 - mse: 2407535297606036282671104.0000 - auc: 0.6466[20582, 21913, 5481, 8594, 14659, 10434, 16439, 21468, 24418, 13728]\n",
      "max255.0\n",
      "min0.0\n",
      "  65/3281 [..............................] - ETA: 22:13 - loss: 10799855899.9202 - accuracy: 0.8669 - mse: 4740992506237321130016768.0000 - auc: 0.6473[1082, 3717, 26016, 22322, 8722, 6830, 18080, 5543, 23680, 32404]\n",
      "max238.0\n",
      "min0.0\n",
      "  66/3281 [..............................] - ETA: 22:08 - loss: 10636221719.6240 - accuracy: 0.8667 - mse: 4669159443662415377465344.0000 - auc: 0.6479[32131, 10664, 14830, 30650, 8101, 3540, 32571, 4776, 31156, 20645]\n",
      "max241.0\n",
      "min0.0\n",
      "  67/3281 [..............................] - ETA: 22:04 - loss: 10477472141.7250 - accuracy: 0.8662 - mse: 4599470526855702208577536.0000 - auc: 0.6484[25133, 28180, 32476, 7427, 15218, 807, 25423, 27671, 14610, 17761]\n",
      "max238.0\n",
      "min0.0\n",
      "  68/3281 [..............................] - ETA: 22:00 - loss: 10323391669.0583 - accuracy: 0.8659 - mse: 4531831216253803861901312.0000 - auc: 0.6490[59, 16122, 17438, 5027, 13824, 13165, 18016, 13281, 18743, 27113]\n",
      "max246.0\n",
      "min0.0\n",
      "  69/3281 [..............................] - ETA: 21:55 - loss: 10173777297.0486 - accuracy: 0.8658 - mse: 4466152448670489458507776.0000 - auc: 0.6496[27443, 777, 20400, 6037, 1793, 18394, 18715, 9628, 1723, 1126]\n",
      "max253.0\n",
      "min0.0\n",
      "  70/3281 [..............................] - ETA: 21:52 - loss: 10028437621.3819 - accuracy: 0.8657 - mse: 4402350349066298850279424.0000 - auc: 0.6501[3979, 14951, 13114, 23087, 989, 4161, 24457, 6057, 19089, 32100]\n",
      "max246.0\n",
      "min0.0\n",
      "  71/3281 [..............................] - ETA: 21:48 - loss: 9887192021.0866 - accuracy: 0.8655 - mse: 4340345365857414164774912.0000 - auc: 0.6507 [5649, 17310, 24940, 12304, 12468, 1902, 30735, 32683, 23855, 17847]\n",
      "max240.0\n",
      "min0.0\n",
      "  72/3281 [..............................] - ETA: 21:44 - loss: 9749869909.6888 - accuracy: 0.8651 - mse: 4280062847376412108652544.0000 - auc: 0.6512[432, 28113, 17245, 15970, 9557, 32448, 8591, 29503, 24412, 13168]\n",
      "max253.0\n",
      "min0.0\n",
      "  73/3281 [..............................] - ETA: 21:41 - loss: 9616310047.9177 - accuracy: 0.8650 - mse: 4221431888950759360823296.0000 - auc: 0.6517[31894, 12452, 10862, 26537, 179, 20474, 22148, 25636, 16437, 18463]\n",
      "max240.0\n",
      "min0.0\n",
      "  74/3281 [..............................] - ETA: 21:37 - loss: 9486359912.1407 - accuracy: 0.8649 - mse: 4164385332902812572450816.0000 - auc: 0.6522[16061, 26725, 10879, 255, 24387, 19220, 31465, 29600, 14456, 12705]\n",
      "max232.0\n",
      "min0.0\n",
      "  75/3281 [..............................] - ETA: 21:33 - loss: 9359875113.3183 - accuracy: 0.8647 - mse: 4108860345010570670374912.0000 - auc: 0.6527[25671, 4167, 26872, 31047, 18100, 32537, 19467, 25006, 28021, 13516]\n",
      "max249.0\n",
      "min0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  76/3281 [..............................] - ETA: 21:29 - loss: 9236718861.8334 - accuracy: 0.8642 - mse: 4054796396895041795129344.0000 - auc: 0.6532[32132, 27540, 9159, 29896, 11518, 18898, 6661, 19315, 28807, 16140]\n",
      "max236.0\n",
      "min0.0\n",
      "  77/3281 [..............................] - ETA: 21:26 - loss: 9116761474.0227 - accuracy: 0.8641 - mse: 4002136707172124059500544.0000 - auc: 0.6537[19643, 28707, 24738, 10411, 19230, 4906, 15227, 2962, 28426, 31727]\n",
      "max249.0\n",
      "min0.0\n",
      "  78/3281 [..............................] - ETA: 21:23 - loss: 8999879916.6695 - accuracy: 0.8638 - mse: 3950827088531100941680640.0000 - auc: 0.6542[27744, 32292, 19683, 19021, 32543, 19859, 18872, 25151, 27169, 4442]\n",
      "max231.0\n",
      "min0.0\n",
      "  79/3281 [..............................] - ETA: 21:22 - loss: 8885957386.0845 - accuracy: 0.8635 - mse: 3900816812425769740402688.0000 - auc: 0.6546[8257, 6062, 28506, 7067, 26680, 31011, 17345, 5001, 19704, 1622]\n",
      "max248.0\n",
      "min0.0\n",
      "  80/3281 [..............................] - ETA: 21:19 - loss: 8774882918.7641 - accuracy: 0.8631 - mse: 3852056591461808512958464.0000 - auc: 0.6551[30933, 27216, 25553, 11897, 10869, 19258, 557, 26246, 22147, 13097]\n",
      "max231.0\n",
      "min0.0\n",
      "  81/3281 [..............................] - ETA: 21:17 - loss: 8666551030.8833 - accuracy: 0.8630 - mse: 3804500308779032985468928.0000 - auc: 0.6556[7552, 11966, 2491, 16041, 14090, 22981, 17793, 3622, 24007, 27613]\n",
      "max230.0\n",
      "min0.0\n",
      "  82/3281 [..............................] - ETA: 21:16 - loss: 8560861384.1704 - accuracy: 0.8628 - mse: 3758103865129891946037248.0000 - auc: 0.6560[10236, 13974, 2418, 17943, 18098, 16906, 2743, 22217, 23513, 27588]\n",
      "max245.0\n",
      "min0.0\n",
      "  83/3281 [..............................] - ETA: 21:13 - loss: 8457718475.9327 - accuracy: 0.8626 - mse: 3712825467109843396460544.0000 - auc: 0.6565[19238, 14616, 32122, 12115, 6789, 10394, 32356, 30403, 22764, 8663]\n",
      "max232.0\n",
      "min0.0\n",
      "  84/3281 [..............................] - ETA: 21:10 - loss: 8357031351.2245 - accuracy: 0.8623 - mse: 3668625338926978400518144.0000 - auc: 0.6569[27590, 15852, 15971, 22059, 24797, 15297, 776, 28040, 29494, 2642]\n",
      "max254.0\n",
      "min0.0\n",
      "  85/3281 [..............................] - ETA: 21:07 - loss: 8258713335.3328 - accuracy: 0.8621 - mse: 3625464857710892628836352.0000 - auc: 0.6573[21656, 22291, 1850, 31818, 22082, 2639, 30011, 3208, 13548, 7010]\n",
      "max244.0\n",
      "min0.0\n",
      "  86/3281 [..............................] - ETA: 21:04 - loss: 8162681784.9269 - accuracy: 0.8618 - mse: 3583308282894943269158912.0000 - auc: 0.6577[5336, 8389, 23686, 2236, 11667, 21558, 10918, 31575, 28839, 30033]\n",
      "max244.0\n",
      "min0.0\n",
      "  87/3281 [..............................] - ETA: 21:02 - loss: 8068857856.3691 - accuracy: 0.8615 - mse: 3542121026833992116076544.0000 - auc: 0.6581[30953, 19524, 4470, 176, 635, 30674, 14799, 23310, 20654, 14521]\n",
      "max240.0\n",
      "min0.0\n",
      "  88/3281 [..............................] - ETA: 21:00 - loss: 7977166289.8242 - accuracy: 0.8611 - mse: 3501869654804405571026944.0000 - auc: 0.6585[1418, 23673, 3604, 29901, 20115, 18923, 18833, 2495, 952, 6131]\n",
      "max255.0\n",
      "min0.0\n",
      "  89/3281 [..............................] - ETA: 20:58 - loss: 7887535207.9208 - accuracy: 0.8608 - mse: 3462522749695183097430016.0000 - auc: 0.6589[21182, 30195, 19301, 6011, 16820, 8194, 32590, 31264, 2292, 25387]\n",
      "max247.0\n",
      "min0.0\n",
      "  90/3281 [..............................] - ETA: 20:56 - loss: 7799895927.8372 - accuracy: 0.8606 - mse: 3424050335547204917264384.0000 - auc: 0.6593[17134, 5918, 26880, 26259, 9311, 15808, 10053, 13770, 24163, 32120]\n",
      "max250.0\n",
      "min0.0\n",
      "  91/3281 [..............................] - ETA: 20:53 - loss: 7714182785.7772 - accuracy: 0.8605 - mse: 3386423301092479707643904.0000 - auc: 0.6597[20238, 32652, 6291, 12927, 20065, 2244, 14141, 13666, 28880, 27487]\n",
      "max255.0\n",
      "min0.0\n",
      "  92/3281 [..............................] - ETA: 20:51 - loss: 7630332972.8923 - accuracy: 0.8604 - mse: 3349614264445273055952896.0000 - auc: 0.6600[8715, 11877, 5612, 13723, 29617, 1642, 8707, 31733, 31836, 5661]\n",
      "max241.0\n",
      "min0.0\n",
      "  93/3281 [..............................] - ETA: 20:49 - loss: 7548286381.7901 - accuracy: 0.8602 - mse: 3313596996641355156422656.0000 - auc: 0.6604[1652, 27024, 14875, 19140, 843, 29142, 14767, 3992, 10691, 22911]\n",
      "max235.0\n",
      "min0.0\n",
      "  94/3281 [..............................] - ETA: 20:48 - loss: 7467985462.8388 - accuracy: 0.8601 - mse: 3278345845177248506707968.0000 - auc: 0.6607[21384, 13957, 10980, 8180, 27929, 12995, 15662, 27949, 6638, 23991]\n",
      "max244.0\n",
      "min0.0\n",
      "  95/3281 [..............................] - ETA: 20:46 - loss: 7389375089.5498 - accuracy: 0.8599 - mse: 3243837175162108666445824.0000 - auc: 0.6611[23624, 16761, 28525, 26137, 12012, 24958, 10537, 11012, 6410, 4488]\n",
      "max242.0\n",
      "min0.0\n",
      "  96/3281 [..............................] - ETA: 20:44 - loss: 7312402432.3707 - accuracy: 0.8599 - mse: 3210047063474715043561472.0000 - auc: 0.6614[30328, 31776, 18041, 1402, 351, 23721, 6665, 28035, 10325, 5843]\n",
      "max255.0\n",
      "min0.0\n",
      "  97/3281 [..............................] - ETA: 20:42 - loss: 7237016840.2880 - accuracy: 0.8599 - mse: 3176953892836856259674112.0000 - auc: 0.6618[8158, 23519, 32727, 29933, 19979, 32094, 26648, 29268, 13390, 8616]\n",
      "max238.0\n",
      "min0.0\n",
      "  98/3281 [..............................] - ETA: 20:41 - loss: 7163169729.6766 - accuracy: 0.8598 - mse: 3144535757739944784691200.0000 - auc: 0.6621[17, 3705, 32437, 869, 28863, 15458, 27818, 1818, 13643, 7980]\n",
      "max255.0\n",
      "min0.0\n",
      "  99/3281 [..............................] - ETA: 20:40 - loss: 7090814479.8855 - accuracy: 0.8599 - mse: 3112772770288026150502400.0000 - auc: 0.6624[8201, 29547, 23057, 19935, 32061, 22138, 25445, 11355, 25179, 20988]\n",
      "max243.0\n",
      "min0.0\n",
      " 100/3281 [..............................] - ETA: 20:37 - loss: 7019906335.0904 - accuracy: 0.8599 - mse: 3081645042585145888997376.0000 - auc: 0.6628[9650, 30525, 27019, 24475, 8833, 22743, 23685, 9119, 28988, 10801]\n",
      "max247.0\n",
      "min0.0\n",
      " 101/3281 [..............................] - ETA: 20:35 - loss: 6950402311.9744 - accuracy: 0.8598 - mse: 3051133839656854138912768.0000 - auc: 0.6631[14169, 4605, 11286, 6180, 13085, 8524, 32285, 569, 29659, 11024]\n",
      "max242.0\n",
      "min0.0\n",
      " 102/3281 [..............................] - ETA: 20:33 - loss: 6882261112.8408 - accuracy: 0.8599 - mse: 3021220714759077190696960.0000 - auc: 0.6634[32420, 24758, 9125, 7331, 9833, 15870, 10826, 5113, 30512, 21818]\n",
      "max255.0\n",
      "min0.0\n",
      " 103/3281 [..............................] - ETA: 20:31 - loss: 6815443043.7875 - accuracy: 0.8599 - mse: 2991888662299622093357056.0000 - auc: 0.6637[32510, 8511, 31216, 31710, 30741, 22482, 22559, 7823, 14390, 1305]\n",
      "max239.0\n",
      "min0.0\n",
      " 104/3281 [..............................] - ETA: 20:29 - loss: 6749909937.6007 - accuracy: 0.8599 - mse: 2963120388455919744188416.0000 - auc: 0.6640[]\n",
      "max0.0\n",
      "min0.0\n",
      " 105/3281 [..............................] - ETA: 20:27 - loss: 6685625081.0555 - accuracy: 0.8601 - mse: 2934900040557281799045120.0000 - auc: 0.6643[29710, 13358, 20460, 17479, 3337, 17325, 7542, 25618, 32376, 16314]\n",
      "max235.0\n",
      "min0.0\n",
      " 106/3281 [..............................] - ETA: 20:25 - loss: 6622553146.3320 - accuracy: 0.8602 - mse: 2907212342393772217204736.0000 - auc: 0.6646[30177, 13027, 24773, 3133, 14244, 12423, 17092, 10400, 6466, 1090]\n",
      "max249.0\n",
      "min0.0\n",
      " 107/3281 [..............................] - ETA: 20:23 - loss: 6560660126.2762 - accuracy: 0.8603 - mse: 2880042305985831109656576.0000 - auc: 0.6649[15078, 1016, 19471, 8991, 23169, 10349, 13620, 25080, 24441, 15288]\n",
      "max230.0\n",
      "min0.0\n",
      " 108/3281 [..............................] - ETA: 20:22 - loss: 6499913273.2586 - accuracy: 0.8603 - mse: 2853375231584274739101696.0000 - auc: 0.6651[19101, 1068, 549, 19793, 12562, 11924, 20634, 12492, 28043, 21648]\n",
      "max226.0\n",
      "min0.0\n",
      " 109/3281 [..............................] - ETA: 20:21 - loss: 6440281041.3973 - accuracy: 0.8603 - mse: 2827197284131047823376384.0000 - auc: 0.6654[23016, 14446, 30199, 19478, 5807, 2080, 12430, 22617, 13705, 16949]\n",
      "max247.0\n",
      "min0.0\n",
      " 110/3281 [>.............................] - ETA: 20:19 - loss: 6381733031.9331 - accuracy: 0.8605 - mse: 2801495493259223535452160.0000 - auc: 0.6657[23580, 12638, 17192, 30986, 28100, 30027, 31985, 11671, 5791, 22352]\n",
      "max228.0\n",
      "min0.0\n",
      " 111/3281 [>.............................] - ETA: 20:18 - loss: 6324239941.5583 - accuracy: 0.8606 - mse: 2776256888601875048300544.0000 - auc: 0.6660[15700, 15236, 17475, 10881, 12998, 13784, 10089, 27066, 20990, 17262]\n",
      "max228.0\n",
      "min0.0\n",
      " 112/3281 [>.............................] - ETA: 20:16 - loss: 6267773513.5119 - accuracy: 0.8608 - mse: 2751468788022451686604800.0000 - auc: 0.6662[14625, 22684, 21080, 14802, 11417, 22073, 23051, 10147, 18126, 10489]\n",
      "max247.0\n",
      "min0.0\n",
      " 113/3281 [>.............................] - ETA: 20:16 - loss: 6212306491.2715 - accuracy: 0.8609 - mse: 2727119662305907381895168.0000 - auc: 0.6665[7070, 16217, 19323, 1361, 20462, 7784, 9651, 26288, 385, 29905]\n",
      "max243.0\n",
      "min0.0\n",
      " 114/3281 [>.............................] - ETA: 20:14 - loss: 6157812574.6844 - accuracy: 0.8610 - mse: 2703197405776443762278400.0000 - auc: 0.6667[9313, 29812, 5298, 30202, 30844, 27683, 2281, 14427, 16210, 30635]\n",
      "max250.0\n",
      "min0.0\n",
      " 115/3281 [>.............................] - ETA: 20:13 - loss: 6104266378.3859 - accuracy: 0.8611 - mse: 2679691353910143214419968.0000 - auc: 0.6670[7944, 32323, 19027, 15224, 2026, 31592, 4255, 18628, 6898, 18339]\n",
      "max255.0\n",
      "min0.0\n",
      " 116/3281 [>.............................] - ETA: 20:12 - loss: 22972695093.3308 - accuracy: 0.8612 - mse: 3984886119159444111622144.0000 - auc: 0.6672[23382, 5359, 7207, 26940, 27940, 9390, 32722, 11952, 23586, 15969]\n",
      "max250.0\n",
      "min0.0\n",
      " 117/3281 [>.............................] - ETA: 20:11 - loss: 22776347272.0233 - accuracy: 0.8614 - mse: 3950827088531100941680640.0000 - auc: 0.6675[25644, 30472, 19211, 18245, 15324, 25450, 30701, 22186, 15190, 6991]\n",
      "max219.0\n",
      "min0.0\n",
      " 118/3281 [>.............................] - ETA: 20:10 - loss: 22583327379.8906 - accuracy: 0.8615 - mse: 3917345671576565802074112.0000 - auc: 0.6677[269, 14025, 22446, 17446, 16771, 6901, 31145, 8532, 11404, 11881]\n",
      "max247.0\n",
      "min0.0\n",
      " 119/3281 [>.............................] - ETA: 20:09 - loss: 22393551519.5588 - accuracy: 0.8615 - mse: 3884426592085902652080128.0000 - auc: 0.6679[6152, 22117, 22847, 28806, 2628, 14913, 31105, 6108, 17772, 9936]\n",
      "max246.0\n",
      "min0.0\n",
      " 120/3281 [>.............................] - ETA: 20:09 - loss: 22206938590.2322 - accuracy: 0.8615 - mse: 3852056591461808512958464.0000 - auc: 0.6682[26669, 32328, 7884, 27108, 32429, 30182, 23735, 24878, 8256, 6323]\n",
      "max245.0\n",
      "min0.0\n",
      " 121/3281 [>.............................] - ETA: 20:08 - loss: 22023410172.1341 - accuracy: 0.8615 - mse: 3820221258185475799121920.0000 - auc: 0.6684[16626, 7700, 25122, 18936, 30354, 9098, 3379, 21297, 11204, 15445]\n",
      "max240.0\n",
      "min0.0\n",
      " 122/3281 [>.............................] - ETA: 20:06 - loss: 21842890416.6277 - accuracy: 0.8615 - mse: 3788907910120353835253760.0000 - auc: 0.6686[29445, 8896, 11625, 17386, 7110, 28058, 11938, 30064, 7716, 24126]\n",
      "max242.0\n",
      "min0.0\n",
      " 123/3281 [>.............................] - ETA: 20:05 - loss: 21665305941.6987 - accuracy: 0.8615 - mse: 3758103865129891946037248.0000 - auc: 0.6689[17454, 17143, 20409, 26354, 40, 17407, 22024, 27186, 29083, 17895]\n",
      "max255.0\n",
      "min0.0\n",
      " 124/3281 [>.............................] - ETA: 20:03 - loss: 21490585732.4949 - accuracy: 0.8614 - mse: 3727796729307915607867392.0000 - auc: 0.6691[24776, 10377, 15338, 6248, 25712, 18741, 14337, 6362, 32797, 21367]\n",
      "max249.0\n",
      "min0.0\n",
      " 125/3281 [>.............................] - ETA: 20:03 - loss: 21318661046.6378 - accuracy: 0.8614 - mse: 3697974108748250297139200.0000 - auc: 0.6693[7859, 19243, 821, 6188, 24561, 17760, 4899, 3223, 384, 31494]\n",
      "max238.0\n",
      "min0.0\n",
      " 126/3281 [>.............................] - ETA: 20:02 - loss: 21149465324.0484 - accuracy: 0.8613 - mse: 3668625338926978400518144.0000 - auc: 0.6695[13693, 23381, 20011, 29254, 7006, 15833, 9422, 16682, 27932, 1649]\n",
      "max233.0\n",
      "min0.0\n",
      " 127/3281 [>.............................] - ETA: 20:01 - loss: 20982934101.0277 - accuracy: 0.8612 - mse: 3639738314168301546110976.0000 - auc: 0.6697[5522, 29815, 30642, 16864, 25440, 7670, 11611, 3796, 2477, 22035]\n",
      "max236.0\n",
      "min0.0\n",
      " 128/3281 [>.............................] - ETA: 20:00 - loss: 20819004928.3671 - accuracy: 0.8610 - mse: 3611302946409054424006656.0000 - auc: 0.6699[18944, 927, 19933, 611, 7353, 12519, 5847, 23170, 18616, 8192]\n",
      "max240.0\n",
      "min0.0\n",
      " 129/3281 [>.............................] - ETA: 19:59 - loss: 20657617293.2665 - accuracy: 0.8608 - mse: 3583308282894943269158912.0000 - auc: 0.6701[20950, 16296, 28418, 13273, 18139, 6705, 138, 19612, 25809, 13964]\n",
      "max244.0\n",
      "min0.0\n",
      " 130/3281 [>.............................] - ETA: 19:58 - loss: 20498712544.8597 - accuracy: 0.8608 - mse: 3555744523793178923368448.0000 - auc: 0.6704[6368, 2442, 21463, 17556, 19578, 16083, 21570, 32726, 27133, 15225]\n",
      "max245.0\n",
      "min0.0\n",
      " 131/3281 [>.............................] - ETA: 19:57 - loss: 20342233823.1463 - accuracy: 0.8608 - mse: 3528601292810219925012480.0000 - auc: 0.6706[2314, 32494, 12846, 8683, 15401, 24428, 7319, 26969, 3599, 24448]\n",
      "max255.0\n",
      "min0.0\n",
      " 132/3281 [>.............................] - ETA: 19:55 - loss: 20188125991.1559 - accuracy: 0.8607 - mse: 3501869654804405571026944.0000 - auc: 0.6708[26104, 20188, 360, 1415, 25754, 32477, 2111, 25286, 20935, 18667]\n",
      "max225.0\n",
      "min0.0\n",
      " 133/3281 [>.............................] - ETA: 19:54 - loss: 20036335570.1729 - accuracy: 0.8606 - mse: 3475539809942946703212544.0000 - auc: 0.6710[7647, 18873, 6779, 16341, 22339, 13565, 30154, 27077, 7378, 26998]\n",
      "max241.0\n",
      "min0.0\n",
      " 134/3281 [>.............................] - ETA: 19:53 - loss: 19886810677.8612 - accuracy: 0.8604 - mse: 3449602823084182618505216.0000 - auc: 0.6712[1799, 888, 18614, 20623, 8863, 10777, 14140, 31935, 32081, 28480]\n",
      "max237.0\n",
      "min0.0\n",
      " 135/3281 [>.............................] - ETA: 19:52 - loss: 19739500969.1393 - accuracy: 0.8603 - mse: 3424050335547204917264384.0000 - auc: 0.6714[24345, 13653, 20140, 6706, 12989, 555, 24006, 30194, 368, 12668]\n",
      "max248.0\n",
      "min0.0\n",
      " 136/3281 [>.............................] - ETA: 19:51 - loss: 19594357579.6634 - accuracy: 0.8603 - mse: 3398873412190352896425984.0000 - auc: 0.6716[19579, 21430, 988, 17803, 27819, 11947, 3349, 5364, 21814, 26719]\n",
      "max238.0\n",
      "min0.0\n",
      " 137/3281 [>.............................] - ETA: 19:50 - loss: 19451333071.7855 - accuracy: 0.8603 - mse: 3374063982563094308061184.0000 - auc: 0.6718[30659, 3865, 30143, 19007, 18219, 11747, 22947, 12841, 12473, 25522]\n",
      "max249.0\n",
      "min0.0\n",
      " 138/3281 [>.............................] - ETA: 19:49 - loss: 19310381382.8623 - accuracy: 0.8603 - mse: 3349614264445273055952896.0000 - auc: 0.6720[430, 27433, 5760, 10083, 942, 7383, 31805, 9211, 15335, 15647]\n",
      "max235.0\n",
      "min0.0\n",
      " 139/3281 [>.............................] - ETA: 19:47 - loss: 19171457775.7939 - accuracy: 0.8603 - mse: 3325516475616733043884032.0000 - auc: 0.6722[18903, 27198, 2576, 114, 5895, 31576, 21027, 32611, 5384, 19051]\n",
      "max248.0\n",
      "min0.0\n",
      " 140/3281 [>.............................] - ETA: 19:46 - loss: 19034518791.6840 - accuracy: 0.8603 - mse: 3301762833857318175637504.0000 - auc: 0.6723[4880, 17212, 1705, 19654, 19964, 2147, 31545, 22999, 10576, 20684]\n",
      "max246.0\n",
      "min0.0\n",
      " 141/3281 [>.............................] - ETA: 19:45 - loss: 18899522204.5120 - accuracy: 0.8601 - mse: 3278345845177248506707968.0000 - auc: 0.6725[6869, 19562, 25195, 11447, 8536, 23492, 20900, 8437, 10006, 27734]\n",
      "max252.0\n",
      "min0.0\n",
      " 142/3281 [>.............................] - ETA: 19:43 - loss: 18766426977.7227 - accuracy: 0.8601 - mse: 3255258880277872547725312.0000 - auc: 0.6727[6433, 7483, 12982, 4472, 5837, 23591, 241, 14987, 14777, 25128]\n",
      "max243.0\n",
      "min0.0\n",
      " 143/3281 [>.............................] - ETA: 19:42 - loss: 18635193222.6367 - accuracy: 0.8600 - mse: 3232495021630162657607680.0000 - auc: 0.6729[14268, 20656, 8060, 8360, 27857, 4587, 8373, 12651, 491, 15675]\n",
      "max241.0\n",
      "min0.0\n",
      " 144/3281 [>.............................] - ETA: 19:40 - loss: 18505782158.5931 - accuracy: 0.8600 - mse: 3210047063474715043561472.0000 - auc: 0.6731[15845, 15180, 10055, 1842, 10254, 7128, 18751, 8547, 32086, 2527]\n",
      "max238.0\n",
      "min0.0\n",
      " 145/3281 [>.............................] - ETA: 19:39 - loss: 18378156074.7438 - accuracy: 0.8599 - mse: 3187908664743254367928320.0000 - auc: 0.6733[20515, 26795, 6258, 15411, 13724, 1493, 19380, 23694, 12653, 14218]\n",
      "max236.0\n",
      "min0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 146/3281 [>.............................] - ETA: 19:38 - loss: 18252278293.4128 - accuracy: 0.8598 - mse: 3166073772597881444761600.0000 - auc: 0.6734[31687, 13204, 29664, 25495, 22722, 18425, 31114, 3392, 22041, 20342]\n",
      "max248.0\n",
      "min0.0\n",
      " 147/3281 [>.............................] - ETA: 19:37 - loss: 18128113134.9571 - accuracy: 0.8598 - mse: 3144535757739944784691200.0000 - auc: 0.6736[7118, 26606, 23627, 23932, 6110, 25342, 12740, 22056, 14323, 1208]\n",
      "max249.0\n",
      "min0.0\n",
      " 148/3281 [>.............................] - ETA: 19:35 - loss: 18005625884.0479 - accuracy: 0.8596 - mse: 3123289143792297505193984.0000 - auc: 0.6738[4461, 3481, 30133, 6758, 21681, 19945, 32130, 24669, 27184, 32518]\n",
      "max249.0\n",
      "min0.0\n",
      " 149/3281 [>.............................] - ETA: 19:34 - loss: 17884782757.3120 - accuracy: 0.8596 - mse: 3102327301456288116899840.0000 - auc: 0.6739[72, 11572, 21536, 12762, 10410, 22899, 31775, 1335, 9848, 19713]\n",
      "max255.0\n",
      "min0.0\n",
      " 150/3281 [>.............................] - ETA: 19:33 - loss: 17765550872.2658 - accuracy: 0.8596 - mse: 3081645042585145888997376.0000 - auc: 0.6741[15838, 3509, 3913, 9975, 9127, 18055, 5682, 6103, 21544, 32305]\n",
      "max228.0\n",
      "min0.0\n",
      " 151/3281 [>.............................] - ETA: 19:31 - loss: 17647898217.4849 - accuracy: 0.8596 - mse: 3061236890801723938963456.0000 - auc: 0.6743[9275, 6589, 8281, 6622, 10109, 32071, 1161, 20012, 26699, 1909]\n",
      "max219.0\n",
      "min0.0\n",
      " 152/3281 [>.............................] - ETA: 19:30 - loss: 17531793623.9513 - accuracy: 0.8596 - mse: 3041097081498499232563200.0000 - auc: 0.6744[2888, 30786, 21327, 24875, 8449, 16077, 16141, 22592, 3898, 3916]\n",
      "max241.0\n",
      "min0.0\n",
      " 153/3281 [>.............................] - ETA: 19:29 - loss: 17417206737.5228 - accuracy: 0.8596 - mse: 3021220714759077190696960.0000 - auc: 0.6746[13077, 20787, 17485, 10041, 18372, 15043, 22452, 7144, 8755, 24804]\n",
      "max244.0\n",
      "min0.0\n",
      " 154/3281 [>.............................] - ETA: 19:27 - loss: 17304107992.4764 - accuracy: 0.8596 - mse: 3001602314206310930841600.0000 - auc: 0.6748[10868, 28450, 22137, 24796, 10277, 16365, 23212, 27097, 11362, 21377]\n",
      "max245.0\n",
      "min0.0\n",
      " 155/3281 [>.............................] - ETA: 19:26 - loss: 17192468586.0757 - accuracy: 0.8596 - mse: 2982237268154182025609216.0000 - auc: 0.6749[18646, 13633, 16599, 14004, 3833, 18707, 14377, 675, 20842, 12767]\n",
      "max255.0\n",
      "min0.0\n",
      " 156/3281 [>.............................] - ETA: 19:25 - loss: 17082260454.1160 - accuracy: 0.8597 - mse: 2963120388455919744188416.0000 - auc: 0.6751[23779, 27913, 21695, 17937, 13627, 26292, 11682, 2228, 32503, 30767]\n",
      "max245.0\n",
      "min0.0\n",
      " 157/3281 [>.............................] - ETA: 19:24 - loss: 16973456247.4041 - accuracy: 0.8598 - mse: 2944247063425505659191296.0000 - auc: 0.6752[13338, 4867, 1817, 19331, 9329, 19310, 17122, 30420, 15681, 5037]\n",
      "max237.0\n",
      "min0.0\n",
      " 158/3281 [>.............................] - ETA: 19:23 - loss: 16866029309.1318 - accuracy: 0.8598 - mse: 2925612393146545191518208.0000 - auc: 0.6754[3903, 17992, 29549, 6341, 6400, 4171, 20671, 11813, 2844, 19425]\n",
      "max240.0\n",
      "min0.0\n",
      " 159/3281 [>.............................] - ETA: 19:22 - loss: 16759953653.1019 - accuracy: 0.8597 - mse: 2907212342393772217204736.0000 - auc: 0.6755[7259, 10541, 20250, 24036, 2918, 3667, 26232, 704, 7079, 28768]\n",
      "max255.0\n",
      "min0.0\n",
      " 160/3281 [>.............................] - ETA: 19:21 - loss: 16655203942.7724 - accuracy: 0.8597 - mse: 2889042299481168308862976.0000 - auc: 0.6757[4862, 31444, 2391, 31378, 31824, 15574, 16215, 3216, 157, 22240]\n",
      "max255.0\n",
      "min0.0\n",
      " 161/3281 [>.............................] - ETA: 19:19 - loss: 16551755471.0806 - accuracy: 0.8597 - mse: 2871097940953091190816768.0000 - auc: 0.6758[16106, 19948, 17079, 1046, 17603, 17227, 25398, 5271, 1779, 32207]\n",
      "max232.0\n",
      "min0.0\n",
      " 162/3281 [>.............................] - ETA: 19:18 - loss: 16449584141.0145 - accuracy: 0.8597 - mse: 2853375231584274739101696.0000 - auc: 0.6760[18222, 28701, 9017, 2794, 26443, 9534, 6739, 4614, 5976, 18170]\n",
      "max236.0\n",
      "min0.0\n",
      " 163/3281 [>.............................] - ETA: 19:17 - loss: 16348666446.9003 - accuracy: 0.8598 - mse: 2835869847919076678041600.0000 - auc: 0.6761[26380, 18713, 1615, 29630, 17205, 925, 1483, 13025, 15371, 18375]\n",
      "max228.0\n",
      "min0.0\n",
      " 164/3281 [>.............................] - ETA: 19:16 - loss: 16248979456.3727 - accuracy: 0.8598 - mse: 2818578042962607035383808.0000 - auc: 0.6763[29300, 31644, 10657, 27484, 10013, 31812, 21800, 14536, 12614, 10113]\n",
      "max248.0\n",
      "min0.0\n",
      " 165/3281 [>.............................] - ETA: 19:15 - loss: 16150500793.0029 - accuracy: 0.8598 - mse: 2801495493259223535452160.0000 - auc: 0.6764[8336, 15503, 12392, 26618, 8262, 21766, 14786, 6740, 3738, 24594]\n",
      "max229.0\n",
      "min0.0\n",
      " 166/3281 [>.............................] - ETA: 19:13 - loss: 16053208619.5532 - accuracy: 0.8598 - mse: 2784619028274788509417472.0000 - auc: 0.6766[16603, 12619, 14415, 22857, 23406, 30301, 8842, 2549, 11021, 16175]\n",
      "max250.0\n",
      "min0.0\n",
      " 167/3281 [>.............................] - ETA: 19:12 - loss: 15957081621.8336 - accuracy: 0.8598 - mse: 2767944901014411985027072.0000 - auc: 0.6767[]\n",
      "max0.0\n",
      "min0.0\n",
      " 168/3281 [>.............................] - ETA: 19:11 - loss: 15862098993.1346 - accuracy: 0.8599 - mse: 2751468788022451686604800.0000 - auc: 0.6768[5745, 6069, 5083, 6637, 27626, 11076, 4792, 3072, 7460, 16397]\n",
      "max232.0\n",
      "min0.0\n",
      " 169/3281 [>.............................] - ETA: 19:10 - loss: 15768240419.2129 - accuracy: 0.8599 - mse: 2735188095225522248744960.0000 - auc: 0.6770[18791, 27936, 31510, 15041, 28158, 14396, 7341, 7576, 3955, 20664]\n",
      "max246.0\n",
      "min0.0\n",
      " 170/3281 [>.............................] - ETA: 19:09 - loss: 15675486063.8078 - accuracy: 0.8600 - mse: 2719098787398357547483136.0000 - auc: 0.6771[12208, 32790, 24611, 9466, 20418, 6113, 31830, 9530, 15091, 25029]\n",
      "max241.0\n",
      "min0.0\n",
      " 171/3281 [>.............................] - ETA: 19:08 - loss: 15583816554.6649 - accuracy: 0.8599 - mse: 2703197405776443762278400.0000 - auc: 0.6772[30389, 2945, 10385, 10117, 4493, 15766, 31247, 18215, 26738, 2832]\n",
      "max249.0\n",
      "min0.0\n",
      " 172/3281 [>.............................] - ETA: 19:07 - loss: 15493212970.0469 - accuracy: 0.8599 - mse: 2687481356286395527725056.0000 - auc: 0.6774[18714, 2029, 30996, 981, 8385, 22607, 13011, 966, 27675, 19318]\n",
      "max242.0\n",
      "min0.0\n",
      " 173/3281 [>.............................] - ETA: 19:06 - loss: 15403656825.7135 - accuracy: 0.8599 - mse: 2671946603702946719858688.0000 - auc: 0.6775[]\n",
      "max0.0\n",
      "min0.0\n",
      " 174/3281 [>.............................] - ETA: 19:05 - loss: 15315130062.3494 - accuracy: 0.8600 - mse: 2656590553952711973273600.0000 - auc: 0.6776[16265, 20419, 12378, 6102, 4124, 15427, 26779, 5182, 25707, 18108]\n",
      "max244.0\n",
      "min0.0\n",
      " 175/3281 [>.............................] - ETA: 19:04 - loss: 15227615033.4238 - accuracy: 0.8600 - mse: 2641410036501553619140608.0000 - auc: 0.6778[1038, 10571, 17838, 826, 20728, 14813, 12622, 19053, 19904, 7875]\n",
      "max236.0\n",
      "min0.0\n",
      " 176/3281 [>.............................] - ETA: 19:03 - loss: 15141094493.4631 - accuracy: 0.8601 - mse: 2626402169045710140342272.0000 - auc: 0.6779[32555, 25470, 25373, 9333, 3829, 17693, 27033, 15778, 28268, 3168]\n",
      "max254.0\n",
      "min0.0\n",
      " 177/3281 [>.............................] - ETA: 19:02 - loss: 15055551586.7225 - accuracy: 0.8600 - mse: 2611563781051043868049408.0000 - auc: 0.6780[917, 18913, 4854, 715, 14535, 18595, 3725, 8752, 16892, 18697]\n",
      "max238.0\n",
      "min0.0\n",
      " 178/3281 [>.............................] - ETA: 19:01 - loss: 14970969836.2373 - accuracy: 0.8600 - mse: 2596891990213793285144576.0000 - auc: 0.6781[22581, 25913, 11435, 16036, 10602, 15021, 3640, 15412, 32379, 18613]\n",
      "max244.0\n",
      "min0.0\n",
      " 179/3281 [>.............................] - ETA: 19:00 - loss: 11994472128.0125 - accuracy: 0.8600 - mse: 3443179032690889418866688.0000 - auc: 0.6783[23274, 10347, 22107, 7114, 22794, 12993, 7830, 14267, 20414, 20557]\n",
      "max251.0\n",
      "min0.0\n",
      " 180/3281 [>.............................] - ETA: 18:59 - loss: 11927836171.7479 - accuracy: 0.8599 - mse: 3424050335547204917264384.0000 - auc: 0.6784[20025, 13702, 8008, 24040, 3412, 3511, 4817, 16523, 3497, 19017]\n",
      "max255.0\n",
      "min0.0\n",
      " 181/3281 [>.............................] - ETA: 18:58 - loss: 11861936524.3924 - accuracy: 0.8599 - mse: 3405132911269239620370432.0000 - auc: 0.6785[32052, 7096, 24872, 10778, 15144, 32746, 2172, 24239, 8775, 12598]\n",
      "max235.0\n",
      "min0.0\n",
      " 182/3281 [>.............................] - ETA: 18:56 - loss: 11796761048.9857 - accuracy: 0.8598 - mse: 3386423301092479707643904.0000 - auc: 0.6786[16546, 1040, 23618, 18718, 28679, 23464, 7136, 4138, 32515, 8131]\n",
      "max238.0\n",
      "min0.0\n",
      " 183/3281 [>.............................] - ETA: 18:56 - loss: 11732297873.8569 - accuracy: 0.8597 - mse: 3367918334482787510255616.0000 - auc: 0.6788[4211, 12123, 10729, 4188, 27729, 31703, 9298, 11158, 5080, 23556]\n",
      "max237.0\n",
      "min0.0\n",
      " 184/3281 [>.............................] - ETA: 18:55 - loss: 11668535385.4145 - accuracy: 0.8597 - mse: 3349614264445273055952896.0000 - auc: 0.6789[32103, 16096, 25768, 17718, 12943, 1903, 10643, 29412, 28558, 26792]\n",
      "max224.0\n",
      "min0.0\n",
      " 185/3281 [>.............................] - ETA: 18:54 - loss: -4993599299.4364 - accuracy: 0.8596 - mse: 4164385332902812572450816.0000 - auc: 0.6790[6535, 31294, 7545, 7143, 19712, 17417, 10976, 11500, 32228, 2223]\n",
      "max241.0\n",
      "min0.0\n",
      " 186/3281 [>.............................] - ETA: 18:53 - loss: -4966751991.3725 - accuracy: 0.8596 - mse: 4141996173744099907600384.0000 - auc: 0.6791[5341, 14442, 19002, 17575, 16449, 17009, 7919, 7622, 21253, 10317]\n",
      "max242.0\n",
      "min0.0\n",
      " 187/3281 [>.............................] - ETA: 18:52 - loss: -4940191820.2932 - accuracy: 0.8595 - mse: 4119846534027969315209216.0000 - auc: 0.6792[24717, 29731, 3022, 2863, 16658, 11151, 3066, 16650, 25915, 2222]\n",
      "max243.0\n",
      "min0.0\n",
      " 188/3281 [>.............................] - ETA: 18:51 - loss: -4913914204.2252 - accuracy: 0.8595 - mse: 4097932378529154671312896.0000 - auc: 0.6794[25130, 6949, 6913, 31639, 6452, 25654, 17696, 13196, 1963, 15454]\n",
      "max240.0\n",
      "min0.0\n",
      " 189/3281 [>.............................] - ETA: 18:50 - loss: -4887914658.1686 - accuracy: 0.8595 - mse: 4076250248483142155370496.0000 - auc: 0.6795[562, 6389, 6843, 10312, 7520, 5574, 6350, 22050, 18175, 13623]\n",
      "max243.0\n",
      "min0.0\n",
      " 190/3281 [>.............................] - ETA: 18:49 - loss: -4862188791.5433 - accuracy: 0.8593 - mse: 4054796396895041795129344.0000 - auc: 0.6796[16924, 22608, 27871, 3191, 10617, 31852, 7968, 31684, 22442, 8220]\n",
      "max255.0\n",
      "min0.0\n",
      " 191/3281 [>.............................] - ETA: 18:48 - loss: -4836732305.7202 - accuracy: 0.8592 - mse: 4033567076769963618336768.0000 - auc: 0.6797[30534, 30490, 15738, 32472, 12233, 1401, 21153, 8655, 27312, 32143]\n",
      "max246.0\n",
      "min0.0\n",
      " 192/3281 [>.............................] - ETA: 18:47 - loss: -4811540991.6247 - accuracy: 0.8591 - mse: 4012558829343393804451840.0000 - auc: 0.6798[22537, 18203, 27638, 13672, 28008, 16956, 23343, 6289, 1737, 11062]\n",
      "max232.0\n",
      "min0.0\n",
      " 193/3281 [>.............................] - ETA: 18:46 - loss: -4786610727.4160 - accuracy: 0.8590 - mse: 3991768484081194684645376.0000 - auc: 0.6800[12977, 31168, 30738, 28816, 29186, 7578, 23240, 28019, 28300, 28645]\n",
      "max232.0\n",
      "min0.0\n",
      " 194/3281 [>.............................] - ETA: 18:45 - loss: -4761937476.2404 - accuracy: 0.8589 - mse: 3971192293988476286664704.0000 - auc: 0.6801[24390, 29663, 29780, 17198, 26639, 13252, 16920, 25661, 7003, 16057]\n",
      "max239.0\n",
      "min0.0\n",
      " 195/3281 [>.............................] - ETA: 18:45 - loss: -4737517284.0508 - accuracy: 0.8588 - mse: 3950827088531100941680640.0000 - auc: 0.6802[12757, 29047, 1191, 15733, 27356, 25560, 27806, 8392, 284, 1822]\n",
      "max239.0\n",
      "min0.0\n",
      " 196/3281 [>.............................] - ETA: 18:44 - loss: -4713346277.4960 - accuracy: 0.8587 - mse: 3930669985405307132575744.0000 - auc: 0.6803[12247, 20982, 26313, 29690, 29840, 28583, 16331, 11904, 13023, 11991]\n",
      "max243.0\n",
      "min0.0\n",
      " 197/3281 [>.............................] - ETA: 18:44 - loss: -4689420661.8707 - accuracy: 0.8586 - mse: 3910717237616204887097344.0000 - auc: 0.6804[30764, 5399, 23868, 29568, 448, 30052, 10061, 5603, 18407, 21227]\n",
      "max248.0\n",
      "min0.0\n",
      " 198/3281 [>.............................] - ETA: 18:43 - loss: -4665736719.1305 - accuracy: 0.8585 - mse: 3890966251090408839839744.0000 - auc: 0.6805[29082, 16610, 32201, 10512, 20417, 20875, 2949, 25524, 10607, 6856]\n",
      "max242.0\n",
      "min0.0\n",
      " 199/3281 [>.............................] - ETA: 18:43 - loss: -4642290805.9655 - accuracy: 0.8584 - mse: 3871413567063405170262016.0000 - auc: 0.6806[7816, 2724, 7069, 22356, 30679, 2215, 18970, 29904, 13549, 20216]\n",
      "max227.0\n",
      "min0.0\n",
      " 200/3281 [>.............................] - ETA: 18:42 - loss: -4619079351.9327 - accuracy: 0.8584 - mse: 3852056591461808512958464.0000 - auc: 0.6807[17362, 22049, 9345, 1484, 16029, 16526, 25305, 4878, 20593, 32718]\n",
      "max242.0\n",
      "min0.0\n",
      " 201/3281 [>.............................] - ETA: 18:41 - loss: -4596098857.6413 - accuracy: 0.8583 - mse: 3832892153751481199099904.0000 - auc: 0.6809[29097, 20175, 2107, 27272, 27597, 27530, 29468, 12419, 31449, 21586]\n",
      "max248.0\n",
      "min0.0\n",
      " 202/3281 [>.............................] - ETA: 18:40 - loss: -4573345892.9957 - accuracy: 0.8582 - mse: 3813917371628661711568896.0000 - auc: 0.6810[29824, 11181, 6543, 3156, 31239, 28200, 16588, 14816, 32111, 7108]\n",
      "max245.0\n",
      "min0.0\n",
      " 203/3281 [>.............................] - ETA: 18:39 - loss: -4550817095.4893 - accuracy: 0.8580 - mse: 3795129651019964684959744.0000 - auc: 0.6811[24592, 3162, 23884, 11086, 29398, 7294, 7088, 19289, 10261, 11115]\n",
      "max247.0\n",
      "min0.0\n",
      " 204/3281 [>.............................] - ETA: 18:38 - loss: -4528509168.5471 - accuracy: 0.8579 - mse: 3776525821391252450443264.0000 - auc: 0.6812[25344, 27331, 29936, 19769, 22354, 11249, 28191, 8646, 11982, 31699]\n",
      "max255.0\n",
      "min0.0\n",
      " 205/3281 [>.............................] - ETA: 18:37 - loss: -4506418879.9158 - accuracy: 0.8577 - mse: 3758103865129891946037248.0000 - auc: 0.6813[5374, 24996, 15871, 12581, 9036, 24009, 15597, 21651, 1675, 30000]\n",
      "max243.0\n",
      "min0.0\n",
      " 206/3281 [>.............................] - ETA: 18:37 - loss: -4484543060.1071 - accuracy: 0.8576 - mse: 3739860611701745502912512.0000 - auc: 0.6814[15390, 5724, 1993, 195, 21713, 22380, 18846, 8649, 15651, 9805]\n",
      "max255.0\n",
      "min0.0\n",
      " 207/3281 [>.............................] - ETA: 18:36 - loss: -4462878600.8764 - accuracy: 0.8575 - mse: 3721793755263803907375104.0000 - auc: 0.6815[4156, 24187, 22610, 12292, 10416, 32541, 10037, 7829, 5429, 26567]\n",
      "max239.0\n",
      "min0.0\n",
      " 208/3281 [>.............................] - ETA: 18:35 - loss: -4441422453.7527 - accuracy: 0.8573 - mse: 3703900413512305642307584.0000 - auc: 0.6816[31968, 28957, 16594, 5137, 15239, 31330, 25165, 13187, 12527, 21198]\n",
      "max238.0\n",
      "min0.0\n",
      " 209/3281 [>.............................] - ETA: 18:34 - loss: -4420171628.6117 - accuracy: 0.8572 - mse: 3686178568834617645727744.0000 - auc: 0.6817[7710, 22600, 29859, 10327, 10453, 8182, 374, 12230, 25822, 8526]\n",
      "max246.0\n",
      "min0.0\n",
      " 210/3281 [>.............................] - ETA: 18:33 - loss: -4399123192.2813 - accuracy: 0.8571 - mse: 3668625338926978400518144.0000 - auc: 0.6818[15275, 20338, 29230, 2823, 4077, 12957, 6454, 10557, 24497, 6226]\n",
      "max219.0\n",
      "min0.0\n",
      " 211/3281 [>.............................] - ETA: 18:32 - loss: -4378274267.1956 - accuracy: 0.8569 - mse: 3651238417946378692984832.0000 - auc: 0.6819[27400, 19771, 5685, 4279, 729, 28010, 25890, 19971, 1394, 15963]\n",
      "max255.0\n",
      "min0.0\n",
      " 212/3281 [>.............................] - ETA: 18:31 - loss: -4357622030.0827 - accuracy: 0.8568 - mse: 3634015500049809309433856.0000 - auc: 0.6820[25928, 23046, 28, 10348, 23828, 31256, 16705, 14294, 29139, 26637]\n",
      "max239.0\n",
      "min0.0\n",
      " 213/3281 [>.............................] - ETA: 18:31 - loss: -4337163710.6892 - accuracy: 0.8567 - mse: 3616954567624637187883008.0000 - auc: 0.6821[32490, 28349, 21908, 1836, 28309, 16806, 11068, 1159, 22800, 32232]\n",
      "max255.0\n",
      "min0.0\n",
      " 214/3281 [>.............................] - ETA: 18:30 - loss: -4316896590.5422 - accuracy: 0.8567 - mse: 3600052738367100811214848.0000 - auc: 0.6822[7456, 11796, 31817, 26920, 28872, 992, 17437, 11477, 20698, 18889]\n",
      "max243.0\n",
      "min0.0\n",
      " 215/3281 [>.............................] - ETA: 18:30 - loss: -4296818001.7451 - accuracy: 0.8564 - mse: 3583308282894943269158912.0000 - auc: 0.6823[19941, 22605, 2570, 28128, 15337, 12263, 28116, 31982, 29311, 17027]\n",
      "max233.0\n",
      "min0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 216/3281 [>.............................] - ETA: 18:29 - loss: -4276925325.8071 - accuracy: 0.8563 - mse: 3566718895365155348021248.0000 - auc: 0.6824[15921, 2868, 29105, 4797, 6201, 11342, 7746, 11376, 12075, 17315]\n",
      "max240.0\n",
      "min0.0\n",
      " 217/3281 [>.............................] - ETA: 18:29 - loss: -4257215992.5050 - accuracy: 0.8562 - mse: 3550282558165103985819648.0000 - auc: 0.6825[27761, 11935, 1317, 16612, 23318, 9682, 17095, 15446, 8122, 3441]\n",
      "max241.0\n",
      "min0.0\n",
      " 218/3281 [>.............................] - ETA: 18:28 - loss: -4237687478.7747 - accuracy: 0.8562 - mse: 3533996677221403817148416.0000 - auc: 0.6826[27007, 17933, 12949, 11084, 5630, 18157, 18720, 17334, 17798, 18214]\n",
      "max244.0\n",
      "min0.0\n",
      " 219/3281 [=>............................] - ETA: 18:28 - loss: -4218337307.6356 - accuracy: 0.8561 - mse: 3517859811382174083448832.0000 - auc: 0.6827[10725, 8596, 8269, 10721, 9256, 8163, 5796, 9484, 2253, 31151]\n",
      "max252.0\n",
      "min0.0\n",
      " 220/3281 [=>............................] - ETA: 18:27 - loss: -4199163047.1429 - accuracy: 0.8560 - mse: 3501869654804405571026944.0000 - auc: 0.6827[19083, 9643, 3641, 12504, 8414, 15194, 10135, 28992, 23364, 29383]\n",
      "max246.0\n",
      "min0.0\n",
      " 221/3281 [=>............................] - ETA: 18:27 - loss: -4180162309.3702 - accuracy: 0.8560 - mse: 3486023901645089066188800.0000 - auc: 0.6828[27046, 20670, 15082, 20973, 21143, 6130, 20455, 30256, 13735, 26221]\n",
      "max249.0\n",
      "min0.0\n",
      " 222/3281 [=>............................] - ETA: 18:27 - loss: -4161332749.4146 - accuracy: 0.8559 - mse: 3470321110752343810375680.0000 - auc: 0.6829[11920, 9821, 9923, 2752, 2851, 6221, 31646, 7819, 20045, 9947]\n",
      "max236.0\n",
      "min0.0\n",
      " 223/3281 [=>............................] - ETA: 18:26 - loss: -4142672064.4367 - accuracy: 0.8559 - mse: 3454759264513536741605376.0000 - auc: 0.6830[12725, 10519, 23091, 24472, 31685, 1172, 17055, 7778, 5608, 14796]\n",
      "max241.0\n",
      "min0.0\n",
      " 224/3281 [=>............................] - ETA: 18:26 - loss: -4124177992.7177 - accuracy: 0.8558 - mse: 3439336057085658646183936.0000 - auc: 0.6831[12119, 9645, 11908, 30887, 16954, 8849, 26476, 5858, 8825, 5832]\n",
      "max244.0\n",
      "min0.0\n",
      " 225/3281 [=>............................] - ETA: 18:25 - loss: -4105848312.7467 - accuracy: 0.8557 - mse: 3424050335547204917264384.0000 - auc: 0.6832[3059, 2554, 14513, 13069, 30261, 5240, 18084, 24666, 12350, 11309]\n",
      "max238.0\n",
      "min0.0\n",
      " 226/3281 [=>............................] - ETA: 18:24 - loss: -4087680842.3335 - accuracy: 0.8557 - mse: 3408899505824790189441024.0000 - auc: 0.6833[14012, 883, 25509, 14840, 4309, 28955, 19920, 26739, 15802, 12358]\n",
      "max218.0\n",
      "min0.0\n",
      " 227/3281 [=>............................] - ETA: 18:24 - loss: -4069673437.7383 - accuracy: 0.8555 - mse: 3393882414996909855866880.0000 - auc: 0.6834[1299, 25964, 11592, 11780, 16482, 20088, 14542, 28264, 17729, 16240]\n",
      "max239.0\n",
      "min0.0\n",
      " 228/3281 [=>............................] - ETA: 18:23 - loss: -4051823992.8330 - accuracy: 0.8554 - mse: 3378997045450930854559744.0000 - auc: 0.6834[25381, 30382, 21673, 21932, 18083, 14227, 12060, 17673, 20735, 31284]\n",
      "max246.0\n",
      "min0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-60cca6a3203e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_Lipnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdatagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdatagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_valid_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/mouth_recognition/venv/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/mouth_recognition/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/mouth_recognition/venv/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/mouth_recognition/venv/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/mouth_recognition/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/mouth_recognition/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/mouth_recognition/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/mouth_recognition/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/mouth_recognition/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/Dokumente/mouth_recognition/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = get_Lipnet(n_classes=51, summary=False)\n",
    "    datagen = DataGenerator(batch_size=10, val_split=0.99)\n",
    "    model.fit_generator(generator=datagen, epochs=1, shuffle=True, validation_data=datagen.get_valid_data())\n",
    "    model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
